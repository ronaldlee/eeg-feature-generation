{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f620c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 15:04:43.487986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (40071, 3446)\n",
      "bb: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, concatenate, Input, Dropout, LSTM, Bidirectional,BatchNormalization,PReLU,ReLU,Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "\n",
    "\n",
    "init_df = pd.read_csv('csv/out_gameemo.csv',  sep=',')\n",
    "\n",
    "print('Shape of data: ', init_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9eb7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_4  \\\n",
      "0     0.165685    -0.852441     0.305529     0.069311    -0.820157   \n",
      "1    -1.280358    -3.529726     1.199699    -1.149790     0.738967   \n",
      "2     1.830922    -1.242559     0.019590    -0.955141     4.069830   \n",
      "3     0.726474    -0.013534     3.577241    -1.806816     0.604612   \n",
      "4    -0.338823     0.202537    -0.062122    -1.623981    -0.346947   \n",
      "\n",
      "   lag1_mean_5  lag1_mean_6  lag1_mean_7  lag1_mean_8  lag1_mean_9  ...  \\\n",
      "0     0.671192    -0.889876     0.491933    -0.284130     0.031775  ...   \n",
      "1    -4.185435    -1.864589    -0.710929     2.279327     0.201870  ...   \n",
      "2    -8.934466     0.863457     1.437240    -1.496749     0.993456  ...   \n",
      "3    -0.489957     0.936905    -2.145070    -0.171676    -0.505224  ...   \n",
      "4    -0.717592    -1.123954    -1.435684     0.115600    -1.780939  ...   \n",
      "\n",
      "   freq_669_12  freq_679_12  freq_689_12  freq_699_12  freq_709_12  \\\n",
      "0     0.010112     0.002127     0.010123     0.004699     0.003033   \n",
      "1     0.005829     0.003433     0.004874     0.005820     0.006687   \n",
      "2     0.006117     0.001497     0.001546     0.003125     0.001843   \n",
      "3     0.006868     0.007770     0.005496     0.006147     0.006058   \n",
      "4     0.015303     0.015246     0.012165     0.007093     0.005732   \n",
      "\n",
      "   freq_720_12  freq_730_12  freq_740_12  freq_750_12  Label  \n",
      "0     0.003067     0.003990     0.000784     0.004331  HA_NV  \n",
      "1     0.006809     0.004600     0.006350     0.004204  LA_PV  \n",
      "2     0.002145     0.001894     0.003016     0.001862  LA_NV  \n",
      "3     0.005706     0.003665     0.002062     0.005097  HA_PV  \n",
      "4     0.007846     0.006156     0.023414     0.009717  LA_NV  \n",
      "\n",
      "[5 rows x 3446 columns]\n",
      "Shape of data:  (40071, 3446)\n",
      "features.shape:  (40071, 3445)\n",
      "label.shape:  (40071, 1)\n",
      "Index(['lag1_mean_0', 'lag1_mean_1', 'lag1_mean_2', 'lag1_mean_3',\n",
      "       'lag1_mean_4', 'lag1_mean_5', 'lag1_mean_6', 'lag1_mean_7',\n",
      "       'lag1_mean_8', 'lag1_mean_9',\n",
      "       ...\n",
      "       'freq_669_12', 'freq_679_12', 'freq_689_12', 'freq_699_12',\n",
      "       'freq_709_12', 'freq_720_12', 'freq_730_12', 'freq_740_12',\n",
      "       'freq_750_12', 'Label'],\n",
      "      dtype='object', length=3446)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#HA_PV = high arousal, positive valence\n",
    "#HA_NV = high arousal, negative valence\n",
    "#LA_NV = low arousal, negative valence\n",
    "#LA_PV = low arousal, positive valance\n",
    "label_map = {1:\"HA_PV\", 2:\"HA_NV\", 3:\"LA_NV\", 4:\"LA_PV\"}\n",
    "\n",
    "init_df[\"Label\"] = init_df[\"Label\"].map(label_map)\n",
    "\n",
    "print(init_df.head())\n",
    "\n",
    "features = init_df.iloc[:, :-1]\n",
    "label = init_df.iloc[:, -1:]\n",
    "\n",
    "print('Shape of data: ', init_df.shape)\n",
    "print('features.shape: ', features.shape)\n",
    "print('label.shape: ', label.shape)\n",
    "\n",
    "init_df.head()\n",
    "print(init_df.columns)\n",
    "\n",
    "\n",
    "y = label\n",
    "X = features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=48)\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2fa0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train,x_test,y_test, save_to, epoch = 2):\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=None)\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "        \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    with strategy.scope():\n",
    "#         inputs = tf.keras.Input(shape=(X_train.shape[1],1))\n",
    "#         #ml_model = tf.keras.layers.GRU(256, return_sequences=True)(inputs)\n",
    "#         ml_model = tf.keras.layers.LSTM(256, return_sequences=True)(inputs)\n",
    "#         flat = Flatten()(ml_model)\n",
    "#         outputs = Dense(4, activation='softmax')(flat)\n",
    "#         model = tf.keras.Model(inputs, outputs)\n",
    "#         #model = tf.keras.models.load_model('_best_model.h5')\n",
    "        \n",
    "                \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(256, return_sequences=True))\n",
    "        model.add(Flatten())        \n",
    "        model.add(Dense(4))\n",
    "        model.add(Activation('softmax')) \n",
    "        \n",
    "        model.build(input_shape=(None, X_train.shape[1], 1))\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(model)\n",
    "\n",
    "        opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        mc = ModelCheckpoint(save_to + '_best_model_lstm_all_cat.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "            \n",
    "        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
    "            \n",
    "        model.compile(optimizer=opt_adam,\n",
    "                      loss=['categorical_crossentropy'],\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "    history = model.fit(x_train,y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=epoch,\n",
    "                        validation_data=(x_test,y_test),\n",
    "                        callbacks=[es,mc,lr_schedule])\n",
    "        \n",
    "    saved_model = load_model(save_to + '_best_model_lstm_all_cat.h5')\n",
    "        \n",
    "    return model,history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913c157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 15:05:45.492286: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-26 15:05:45.493740: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-26 15:05:45.582481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:67:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-06-26 15:05:45.583052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-06-26 15:05:45.583090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-26 15:05:45.618516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-26 15:05:45.618666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-26 15:05:45.639222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-26 15:05:45.644111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-26 15:05:45.679759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-26 15:05:45.685496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-26 15:05:45.747271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-26 15:05:45.752789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-06-26 15:05:45.754830: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-26 15:05:45.756702: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-26 15:05:45.956146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:67:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-06-26 15:05:45.956639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-06-26 15:05:45.956675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-26 15:05:45.956690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-26 15:05:45.956700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-26 15:05:45.956709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-26 15:05:45.956719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-26 15:05:45.956728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-26 15:05:45.956738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-26 15:05:45.956747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-26 15:05:45.958563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-06-26 15:05:45.958905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-26 15:05:47.291481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-26 15:05:47.291508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-06-26 15:05:47.291513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-06-26 15:05:47.291516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-06-26 15:05:47.304523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10065 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5)\n",
      "2022-06-26 15:05:47.307633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9875 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3445, 1)]         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 3445, 256)         264192    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 881920)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 3527684   \n",
      "=================================================================\n",
      "Total params: 3,791,876\n",
      "Trainable params: 3,791,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 15:05:48.795140: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_653\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-06-26 15:05:48.813668: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-26 15:05:48.836044: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3299990000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "INFO:tensorflow:batch_all_reduce: 5 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 5 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 15:05:52.861976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-26 15:05:53.433453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - ETA: 0s - loss: 3.7646 - accuracy: 0.4659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 15:07:59.095392: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_7772\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 153s 167ms/step - loss: 3.7623 - accuracy: 0.4659 - val_loss: 1.0648 - val_accuracy: 0.5918\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59183, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 2/40\n",
      "877/877 [==============================] - 146s 166ms/step - loss: 0.9390 - accuracy: 0.6456 - val_loss: 1.0341 - val_accuracy: 0.6293\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.59183 to 0.62935, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 3/40\n",
      "877/877 [==============================] - 145s 166ms/step - loss: 0.7241 - accuracy: 0.7304 - val_loss: 0.8626 - val_accuracy: 0.6996\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.62935 to 0.69963, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 4/40\n",
      "877/877 [==============================] - 146s 166ms/step - loss: 0.5596 - accuracy: 0.7916 - val_loss: 0.8200 - val_accuracy: 0.7287\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.69963 to 0.72875, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 5/40\n",
      "877/877 [==============================] - 145s 166ms/step - loss: 0.4394 - accuracy: 0.8354 - val_loss: 0.9229 - val_accuracy: 0.7169\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72875\n",
      "Epoch 6/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.3343 - accuracy: 0.8742 - val_loss: 0.8342 - val_accuracy: 0.7536\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.72875 to 0.75362, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 7/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.2359 - accuracy: 0.9114 - val_loss: 0.9043 - val_accuracy: 0.7537\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.75362 to 0.75370, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 8/40\n",
      "877/877 [==============================] - 145s 166ms/step - loss: 0.1782 - accuracy: 0.9337 - val_loss: 0.9892 - val_accuracy: 0.7599\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.75370 to 0.75994, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 9/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.1308 - accuracy: 0.9503 - val_loss: 0.9493 - val_accuracy: 0.7713\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.75994 to 0.77125, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 10/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.0851 - accuracy: 0.9713 - val_loss: 1.0365 - val_accuracy: 0.7793\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.77125 to 0.77932, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 11/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.0651 - accuracy: 0.9788 - val_loss: 1.0426 - val_accuracy: 0.7826\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.77932 to 0.78265, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 12/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 1.1296 - val_accuracy: 0.7791\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.78265\n",
      "Epoch 13/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 1.1172 - val_accuracy: 0.7881\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.78265 to 0.78814, saving model to ./_best_model_lstm_all_cat.h5\n",
      "Epoch 14/40\n",
      "877/877 [==============================] - 144s 164ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 1.1716 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78814\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model,history = train_model(X_train, y_train,X_test, y_test, save_to= './', epoch = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9db71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
