{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f620c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 12:17:01.197476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, concatenate, Input, Dropout, LSTM, GRU, Bidirectional,BatchNormalization,PReLU,ReLU,Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c4d774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (8064, 8975)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_df = pd.read_csv('./csv/sample_size_72_output_gameemo.csv',  sep=',')\n",
    "\n",
    "print('Shape of data: ', init_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5562cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_4  \\\n",
      "0     0.692934     1.878464    -2.828129    -5.344069     0.994442   \n",
      "1     3.514797    -0.202528     0.423228    -1.157560     9.616784   \n",
      "2     0.825958    -0.272596    -0.097332    -0.498906    -0.406312   \n",
      "3     0.039585    -0.221452    -0.440229     0.052840    -0.572357   \n",
      "4    -0.222586     0.375803     0.025652    -0.081739     0.358248   \n",
      "\n",
      "   lag1_mean_5  lag1_mean_6  lag1_mean_7  lag1_mean_8  lag1_mean_9  ...  \\\n",
      "0     6.233777    -5.467080     4.490135    -4.166847     0.205733  ...   \n",
      "1    -2.027555     1.855700    -0.571692     0.624903    -0.911293  ...   \n",
      "2     0.258177    -0.299445    -0.886469    -0.023697     0.525584  ...   \n",
      "3    -0.362489     0.350753     0.126999     0.532136     0.316793  ...   \n",
      "4    -0.039733    -0.008091    -0.159095     0.162283    -0.239099  ...   \n",
      "\n",
      "   freq_2540_13  freq_2550_13  freq_2560_13  freq_2570_13  freq_2580_13  \\\n",
      "0      0.000791      0.001970      0.000521      0.001306      0.001990   \n",
      "1      0.000600      0.000546      0.001017      0.001710      0.000753   \n",
      "2      0.000437      0.002748      0.003223      0.000973      0.000648   \n",
      "3      0.001557      0.001283      0.000570      0.001355      0.003288   \n",
      "4      0.000299      0.000212      0.000444      0.000186      0.000426   \n",
      "\n",
      "   freq_2590_13  freq_2600_13  freq_2610_13  freq_2620_13  Label  \n",
      "0      0.001884      0.001027      0.001174      0.000607    2.0  \n",
      "1      0.000618      0.001160      0.000458      0.000354    2.0  \n",
      "2      0.002729      0.002160      0.000614      0.001946    1.0  \n",
      "3      0.001684      0.001401      0.003539      0.002022    3.0  \n",
      "4      0.000157      0.000286      0.000298      0.000420    1.0  \n",
      "\n",
      "[5 rows x 8975 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = init_df.copy()\n",
    "print(df.head())\n",
    "\n",
    "#HA_PV = high arousal, positive valence\n",
    "#HA_NV = high arousal, negative valence\n",
    "#LA_NV = low arousal, negative valence\n",
    "#LA_PV = low arousal, positive valance\n",
    "\n",
    "label_map = {1:\"HA_PV\", 2:\"HA_NV\", 3:\"LA_NV\", 4:\"LA_PV\"}\n",
    "\n",
    "df[\"Label\"] = df[\"Label\"].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9eb7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_4  \\\n",
      "0     0.692934     1.878464    -2.828129    -5.344069     0.994442   \n",
      "1     3.514797    -0.202528     0.423228    -1.157560     9.616784   \n",
      "2     0.825958    -0.272596    -0.097332    -0.498906    -0.406312   \n",
      "3     0.039585    -0.221452    -0.440229     0.052840    -0.572357   \n",
      "4    -0.222586     0.375803     0.025652    -0.081739     0.358248   \n",
      "\n",
      "   lag1_mean_5  lag1_mean_6  lag1_mean_7  lag1_mean_8  lag1_mean_9  ...  \\\n",
      "0     6.233777    -5.467080     4.490135    -4.166847     0.205733  ...   \n",
      "1    -2.027555     1.855700    -0.571692     0.624903    -0.911293  ...   \n",
      "2     0.258177    -0.299445    -0.886469    -0.023697     0.525584  ...   \n",
      "3    -0.362489     0.350753     0.126999     0.532136     0.316793  ...   \n",
      "4    -0.039733    -0.008091    -0.159095     0.162283    -0.239099  ...   \n",
      "\n",
      "   freq_2540_13  freq_2550_13  freq_2560_13  freq_2570_13  freq_2580_13  \\\n",
      "0      0.000791      0.001970      0.000521      0.001306      0.001990   \n",
      "1      0.000600      0.000546      0.001017      0.001710      0.000753   \n",
      "2      0.000437      0.002748      0.003223      0.000973      0.000648   \n",
      "3      0.001557      0.001283      0.000570      0.001355      0.003288   \n",
      "4      0.000299      0.000212      0.000444      0.000186      0.000426   \n",
      "\n",
      "   freq_2590_13  freq_2600_13  freq_2610_13  freq_2620_13  Label  \n",
      "0      0.001884      0.001027      0.001174      0.000607  HA_NV  \n",
      "1      0.000618      0.001160      0.000458      0.000354  HA_NV  \n",
      "2      0.002729      0.002160      0.000614      0.001946  HA_PV  \n",
      "3      0.001684      0.001401      0.003539      0.002022  LA_NV  \n",
      "4      0.000157      0.000286      0.000298      0.000420  HA_PV  \n",
      "\n",
      "[5 rows x 8975 columns]\n",
      "Shape of data:  (8064, 8975)\n",
      "features.shape:  (8064, 8974)\n",
      "label.shape:  (8064, 1)\n",
      "Index(['lag1_mean_0', 'lag1_mean_1', 'lag1_mean_2', 'lag1_mean_3',\n",
      "       'lag1_mean_4', 'lag1_mean_5', 'lag1_mean_6', 'lag1_mean_7',\n",
      "       'lag1_mean_8', 'lag1_mean_9',\n",
      "       ...\n",
      "       'freq_2540_13', 'freq_2550_13', 'freq_2560_13', 'freq_2570_13',\n",
      "       'freq_2580_13', 'freq_2590_13', 'freq_2600_13', 'freq_2610_13',\n",
      "       'freq_2620_13', 'Label'],\n",
      "      dtype='object', length=8975)\n",
      "sample_size: 72\n",
      "num_of_features: 8975\n",
      "total_samples_count: 112\n",
      "train size: 5616\n",
      "test size: 2448\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50397984 into shape (78,72,8975)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X[:train_size], X[train_size:]\n\u001b[1;32m     44\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[:train_size], y[train_size:]\n\u001b[0;32m---> 46\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sample_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_of_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape((test_sample_count,sample_size,num_of_features))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train.shape after reshape:\u001b[39m\u001b[38;5;124m\"\u001b[39m,X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 50397984 into shape (78,72,8975)"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head())\n",
    "\n",
    "features = df.iloc[:, :-1]\n",
    "label = df.iloc[:, -1:]\n",
    "\n",
    "print('Shape of data: ', df.shape)\n",
    "print('features.shape: ', features.shape)\n",
    "print('label.shape: ', label.shape)\n",
    "\n",
    "# df.head()\n",
    "# print(df.columns)\n",
    "\n",
    "y = label.to_numpy()\n",
    "X = features.to_numpy()\n",
    "\n",
    "############################################################\n",
    "# total number of batches: 8064 \n",
    "# timesteps per batch: 72\n",
    "# features: 8975\n",
    "\n",
    "sample_size = 72  \n",
    "num_of_features = 8975\n",
    "\n",
    "train_dataset_percentage = 0.7\n",
    "\n",
    "print(\"sample_size:\",sample_size)\n",
    "print(\"num_of_features:\",num_of_features)\n",
    "\n",
    "total_samples_count = int(X.shape[0]/sample_size)\n",
    "\n",
    "print(\"total_samples_count:\", total_samples_count)\n",
    "\n",
    "\n",
    "train_sample_count = int(total_samples_count * train_dataset_percentage)\n",
    "test_sample_count = total_samples_count - train_sample_count\n",
    "\n",
    "train_size = train_sample_count * sample_size\n",
    "test_size = test_sample_count * sample_size\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"test size:\", test_size)\n",
    "\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "X_train = X_train.reshape((train_sample_count,sample_size,num_of_features))\n",
    "X_test = X_test.reshape((test_sample_count,sample_size,num_of_features))\n",
    "\n",
    "print(\"X_train.shape after reshape:\",X_train.shape)\n",
    "print(\"X_test.shape after reshape:\",X_test.shape)\n",
    "\n",
    "#collapse y_train and y_test to the same X sample counts instead\n",
    "\n",
    "y_train_collapsed = np.array([])\n",
    "for i in range(len(y_train)):\n",
    "    if (i % sample_size == 0):\n",
    "        y_train_collapsed = np.append(y_train_collapsed, (y_train[i]))\n",
    "        \n",
    "print(\"y_train_collapsed shape:\",y_train_collapsed.shape)        \n",
    "\n",
    "y_test_collapsed = np.array([])\n",
    "for i in range(len(y_test)):\n",
    "    if (i % sample_size == 0):\n",
    "        y_test_collapsed = np.append(y_test_collapsed, (y_test[i]))\n",
    "        \n",
    "print(\"y_test_collapsed shape:\",y_test_collapsed.shape)    \n",
    "\n",
    "# one-hot encoding\n",
    "y_train = pd.get_dummies(y_train_collapsed)\n",
    "y_test = pd.get_dummies(y_test_collapsed)\n",
    "\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train,x_test,y_test, save_to, epoch, sample_size, num_of_features):\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=None)\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))  \n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    with strategy.scope():\n",
    "\n",
    "#         inputs = tf.keras.Input(shape=(sample_size,num_of_features))\n",
    "#         #ml_model = tf.keras.layers.GRU(256, return_sequences=True)(inputs)\n",
    "#         ml_model = tf.keras.layers.LSTM(256, return_sequences=True)(inputs)\n",
    "#         flat = Flatten()(ml_model)\n",
    "#         outputs = Dense(4, activation='softmax')(flat)\n",
    "#         model = tf.keras.Model(inputs, outputs)\n",
    "        \n",
    "        ######\n",
    "        #sample size:38252/524, accuracy: 1.0000 - val_loss: 5.5889 - val_accuracy: 0.4403\n",
    "        #sample size:38252/73, loss: 1.4733e-04 - accuracy: 1.0000 - val_loss: 4.6835 - val_accuracy: 0.5475\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(256, return_sequences=True, input_shape=(sample_size,num_of_features)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4))\n",
    "        model.add(Activation('softmax'))        \n",
    "        \n",
    "        ######\n",
    "#         model = Sequential()\n",
    "#         model.add(LSTM(256, return_sequences=True, input_shape=(sample_size,num_of_features), go_backwards=True))\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(4))\n",
    "#         model.add(Activation('softmax'))\n",
    "\n",
    "        ######\n",
    "        \n",
    "#         model = Sequential()\n",
    "#         model.add(Bidirectional(LSTM(256, return_sequences=True), \n",
    "#                                 input_shape=(sample_size,num_of_features))) #, merge_mode='concat'))\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(4))\n",
    "#         model.add(Activation('softmax')) \n",
    "        \n",
    "\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(model)\n",
    "\n",
    "        opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        mc = ModelCheckpoint(save_to + '_best_model_lstm_time_domain.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "            \n",
    "        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
    "            \n",
    "        model.compile(optimizer=opt_adam,\n",
    "                      loss=['categorical_crossentropy'],\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "          \n",
    "    history = model.fit(x_train,y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=epoch,\n",
    "                        validation_data=(x_test,y_test),\n",
    "                        callbacks=[es,mc,lr_schedule], shuffle=False)\n",
    "        \n",
    "    # saved_model = load_model(save_to + '_best_model_lstm_all_cat.h5')\n",
    "        \n",
    "    return model,history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model,history = train_model(X_train, y_train,X_test, y_test, save_to= './', epoch = 40, \n",
    "                            sample_size=sample_size, num_of_features=num_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(history):\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.xticks(range(0, len(history['loss'] + 1)))\n",
    "  plt.plot(history['loss'], label=\"training\", marker='o')\n",
    "  plt.plot(history['val_loss'], label=\"validation\", marker='o')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def plot_accuracy_history(history):\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.xticks(range(0, len(history['accuracy'] + 1)))\n",
    "  plt.plot(history['accuracy'], label=\"training\", marker='o')\n",
    "  plt.plot(history['val_accuracy'], label=\"validation\", marker='o')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_data = pd.DataFrame(history.history)\n",
    "plot_loss_history(history_data)\n",
    "plot_accuracy_history(history_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
